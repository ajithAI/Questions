
# Questions

### Course 1 : Neural Networks & Deep Learning
#### Week 1: 
1.	What is Supervised Fine Tuning? 
2.	What is Structured Data & Unstructured Data? 
3.	Is Audio/Image structured data or unstructured data? 
4.	How Data, Computation capabilities, Algorithms changed over time?
5.	How Relu changed gradient descent algorithm to work much faster? 

#### Week 2:
1.	What is the training algorithm for Binary classification?
2.	Explain Logistic Regression with formula.  
3.	Explain Sigmoid function with formula.
4.	Explain Logistic Regression Loss Function & overall Cost Function (J) with formula.  
5.	Explain Gradient Descent Algorithm with formulas. [ J, w, b, Alpha, dJ/dw ]
6.	Derivative of Sigmoid ( 1 / ( 1 + e ^ -x ) ) ?
7.	Explain Vectorized version of Logistic Regression.

#### Week 3 : 
1.  Describe Input Layer, Hidden Layer & Output Layer in Neural Network.
2.  Write Down the Neural Network Representation for 3 Input, Hidden Layer with 4 Nodes & Output Layer with 1 Node netowrk.
3.  Describe Matrix Dimenssions of the above.
4.  Describe Matrix Dimenssions of the above with m inputs. ( Use Vectorization : x-axis : m , y-axis : dim )
5.  Sigmoid vs Tanh vs ReLu vs Leaky ReLu. What is derivate of ReLu ?
6.  Why we need activation function at all ? What it's purpose ?

### Week 4 : 
1. Give notations of Deep Neural Network. (L, n[L], W[L], a[L], yhat etc.)
2. What are Matrix Dimenssions of DNN. Take an example of 5 Layer DNN and explain the weights dimenssions.
3. What are Matrix Dimenssions of DNN, when "m" inputs stacked as batch.
4. Explain the Intutuion behind DNN with examples. ( First Layers, Middle Layers, Final Layers )
5. Whaty are the Inputs, Output, Cache in forward & backward propagation ?
6. List all the Hyperparameters in DNN.
